{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README.\n",
    "\n",
    "This notebook is the entrypoint for Azure ML enabled training.\n",
    "In its essence, it connects to Azure ML, makes sure that everything is ready over there, and starts the training.\n",
    "To that end, this notebook gathers all necessary sourcecodes in a temp-folder, which will be pushed to Azure ML for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core import Experiment\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create temp folder and copy code.\n",
    "\n",
    "Here you have to be very precise, which code to copy.\n",
    "And most importantly, which code NOT to copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temp folder...\n",
      "Copying files...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating temp folder...\")\n",
    "temp_path = \"tmp_train\"\n",
    "if os.path.exists(temp_path):\n",
    "    shutil.rmtree(temp_path)\n",
    "os.mkdir(temp_path)\n",
    "\n",
    "print(\"Copying files...\")\n",
    "shutil.copy(os.path.join(\"code\", \"train.py\"), temp_path)\n",
    "shutil.copy(os.path.join(\"code\", \"preprocessing.py\"), temp_path)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to azure workspace.\n",
    "\n",
    "Make sure that you have a config.json file with the keys subscription_id, resource_group, and cgm-ml-dev. Either here (not so nice) or in a parent folder (okay but not perfect), or in the root folder of this repo (way to go)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='cgm-azureml-prod', subscription_id='9b82ecea-6780-4b85-8acf-d27d79028f07', resource_group='cgm-ml-prod')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace = Workspace.from_config()\n",
    "workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the experiment.\n",
    "\n",
    "- You should always arrange all your runs in an experiment.\n",
    "- Create at least one experiment per sprint.\n",
    "- Make sure that the name of the experiment reflects the sprint number.\n",
    "- On top of that you could also add other tokens to the name. For example network architecture, dataset name, and/or targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>q2s1-cnndepthmap-height</td><td>cgm-azureml-prod</td><td><a href=\"https://ml.azure.com/experiments/q2s1-cnndepthmap-height?wsid=/subscriptions/9b82ecea-6780-4b85-8acf-d27d79028f07/resourcegroups/cgm-ml-prod/workspaces/cgm-azureml-prod\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: q2s1-cnndepthmap-height,\n",
       "Workspace: cgm-azureml-prod)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = \"q2s1-cnndepthmap-height\"\n",
    "experiment = Experiment(workspace=workspace, name=experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find/create a compute target.\n",
    "\n",
    "Connects to a compute cluster on Azure ML.\n",
    "If the compute cluster does not exist, it will be created.\n",
    "\n",
    "Note: Usually computer clusters autoscale. This means that new nodes are created when necessary. And unused VMs will be shut down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AmlCompute(workspace=Workspace.create(name='cgm-azureml-prod', subscription_id='9b82ecea-6780-4b85-8acf-d27d79028f07', resource_group='cgm-ml-prod'), name=gpu-cluster, id=/subscriptions/9b82ecea-6780-4b85-8acf-d27d79028f07/resourceGroups/cgm-ml-prod/providers/Microsoft.MachineLearningServices/workspaces/cgm-azureml-prod/computes/gpu-cluster, type=AmlCompute, provisioning_state=Succeeded, location=westeurope, tags=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import shutil\n",
    "import azureml\n",
    " \n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "# Compute cluster exists. Just connect to it.\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=workspace, name=cluster_name)\n",
    "    print(\"Found existing compute target.\")\n",
    "\n",
    "# Compute cluster does not exist. Create one.    \n",
    "except ComputeTargetException:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='Standard_NC6', \n",
    "        max_nodes=4\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(workspace, cluster_name, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "compute_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset for training.\n",
    "\n",
    "Here you specify which dataset to use.\n",
    "\n",
    "Note: Double check on Azure ML that you are using the right one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('cgmmlprod', '2020_03_02_15_35_49-depth_npy_azure_ml/**')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"8dc74a9d-b612-4fbc-a0eb-74513c75a880\",\n",
       "    \"name\": \"anon-depthmap-npy\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"depthmap data from old project as numpy arrays with target included\",\n",
       "    \"workspace\": \"Workspace.create(name='cgm-azureml-prod', subscription_id='9b82ecea-6780-4b85-8acf-d27d79028f07', resource_group='cgm-ml-prod')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"anon-depthmap-npy\"\n",
    "dataset = workspace.datasets[dataset_name]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push the training source code to Azure.\n",
    "\n",
    "Creates an estimator (a template for a compute cluster node) and pushes it to the compute cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.10', '1.12', '1.13', '2.0']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.runconfig import MpiConfiguration\n",
    "from azureml.train.dnn import TensorFlow\n",
    "TensorFlow.get_supported_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'--split_seed': 666, '--target_size': '86x112', '--epochs': 1000, '--batch_size': 256}\n",
      "1 {'--split_seed': 666, '--target_size': '129x168', '--epochs': 1000, '--batch_size': 256}\n",
      "2 {'--split_seed': 666, '--target_size': '172x224', '--epochs': 1000, '--batch_size': 256}\n",
      "3 {'--split_seed': 666, '--target_size': '258x336', '--epochs': 1000, '--batch_size': 256}\n"
     ]
    }
   ],
   "source": [
    "# Specify pip packages here.\n",
    "pip_packages = [\n",
    "    \"azureml-dataprep[fuse,pandas]\",\n",
    "    \"glob2\",\n",
    "    #\"tensorflow==2.1.0\"\n",
    "]\n",
    "\n",
    "target_sizes = [\n",
    "    \"86x112\",\n",
    "    \"129x168\",\n",
    "    \"172x224\",\n",
    "    \"258x336\", # Default!\n",
    "    \n",
    "]\n",
    "\n",
    "for index, target_size in enumerate(target_sizes):\n",
    "\n",
    "    script_params = {\n",
    "        \"--split_seed\": 666,\n",
    "        \"--target_size\": target_size,\n",
    "        \"--epochs\": 1000,\n",
    "        \"--batch_size\": 256,\n",
    "    }\n",
    "    print(index, script_params)\n",
    "\n",
    "    # Create the estimator.\n",
    "    estimator = TensorFlow(\n",
    "        source_directory=temp_path,\n",
    "        compute_target=compute_target,\n",
    "        entry_script=\"train.py\",\n",
    "        use_gpu=True,\n",
    "        framework_version=\"2.0\",\n",
    "        inputs=[dataset.as_named_input(\"dataset\").as_mount()],\n",
    "        pip_packages=pip_packages,\n",
    "        script_params=script_params\n",
    "    )\n",
    "\n",
    "    # Set compute target.\n",
    "    estimator.run_config.target = compute_target\n",
    "\n",
    "    # Run the experiment.\n",
    "    run = experiment.submit(estimator)\n",
    "\n",
    "# Show outputs.\n",
    "#from azureml.widgets import RunDetails\n",
    "#RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete temp folder.\n",
    "\n",
    "After all code has been pushed to Azure ML, the temp folder will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
