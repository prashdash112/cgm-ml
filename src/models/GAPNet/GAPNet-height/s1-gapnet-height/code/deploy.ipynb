{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the details before running\n",
    "subscription_id = '.'\n",
    "resource_group = '.'\n",
    "workspace_name = '.'\n",
    "\n",
    "ws = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='cgm-azureml-prod', subscription_id='9b82ecea-6780-4b85-8acf-d27d79028f07', resource_group='cgm-ml-prod')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering the model to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model gapnet_height_s1\n"
     ]
    }
   ],
   "source": [
    "#skip if model is already registered\n",
    "model = Model.register(model_path = \"./GAPNet/\",\n",
    "                       model_name = \"gapnet_height_s1\",\n",
    "                       description = \"GAPNet model trained for predicting height\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the model is already registered in the workspace fetch it using the model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(ws, name='gapnet_height_s1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='cgm-ml-dev', subscription_id='9b82ecea-6780-4b85-8acf-d27d79028f07', resource_group='cgm-ml-dev'), name=gapnet_height_s1, id=gapnet_height_s1:1, version=1, tags={}, properties={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry script for deploying on a AKS(Azure Kubernetes Service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score_aks.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score_aks.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('/structure/azureml-app/azureml-models/gapnet_height_s1/1/')\n",
    "from GAPNet.models import GAPNet\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras import models\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model = GAPNet()\n",
    "    output_directory = '/structure/azureml-app/azureml-models/gapnet_height_s1/1/GAPNet'\n",
    "    model.load_weights(os.path.join(output_directory, \"gapnet_weights.h5\"))\n",
    "    \n",
    "def run(data):\n",
    "    try:\n",
    "        data_list = json.loads(data)\n",
    "        data_np = np.array(data_list['data'])\n",
    "        result = model.predict(data_np)\n",
    "        # You can return any data type, as long as it is JSON serializable.\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry script to deploy to ACI(Azure Container Instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score_aci.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score_aci.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('/var/azureml-app/azureml-models/gapnet_height_s1/1/')\n",
    "from GAPNet.models import GAPNet\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras import models\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model = GAPNet()\n",
    "    output_directory = '/var/azureml-app/azureml-models/gapnet_height_s1/1/GAPNet'\n",
    "    model.load_weights(os.path.join(output_directory, \"gapnet_weights.h5\"))\n",
    "    \n",
    "def run(data):\n",
    "    try:\n",
    "        data_list = json.loads(data)\n",
    "        data_np = np.array(data_list['data'])\n",
    "        result = model.predict(data_np)\n",
    "        # You can return any data type, as long as it is JSON serializable.\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the dependencies required for the model and set inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "env = Environment('GAPNet_height')\n",
    "env.python.conda_dependencies = CondaDependencies.create(conda_packages=['tensorflow==2.0.0'],pip_packages=['azureml-defaults', 'pyntcloud', 'inference_schema', 'opencv-python', 'matplotlib', 'psycopg2-binary', 'tqdm', 'Pillow', 'opencv-python', 'bunch'])\n",
    "inference_config_aci = InferenceConfig(entry_script=\"score_aci.py\", environment=env)\n",
    "inference_config_aks = InferenceConfig(entry_script=\"score_aks.py\", environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.......................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 4)\n",
    "service = Model.deploy(ws, \"aci-gapnet-height-s1-1\", [model], inference_config_aci, deployment_config)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.update(enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/bin/bash: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\nbash: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libtinfo.so.5: no version information available (required by bash)\\n2020-02-27T15:11:12,543892105+00:00 - gunicorn/run \\n2020-02-27T15:11:12,549856697+00:00 - rsyslog/run \\n2020-02-27T15:11:12,562435582+00:00 - nginx/run \\n/usr/sbin/nginx: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n2020-02-27T15:11:12,563768080+00:00 - iot-server/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n/bin/bash: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n2020-02-27T15:11:12,745224156+00:00 - iot-server/finish 1 0\\n2020-02-27T15:11:12,746757554+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (9)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 36\\nInitialized PySpark session.\\ngenerated new fontManager\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user\\'s init function\\nFrom /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nColocations handled automatically by placer.\\nFrom /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\\nInstructions for updating:\\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\\nUser\\'s init function failed\\nEncountered Exception Traceback (most recent call last):\\n  File \"/var/azureml-server/aml_blueprint.py\", line 162, in register\\n    main.init()\\n/azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\\n/azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\\n/azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\\n/azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\\n/azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\\n/azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or \\'1type\\' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / \\'(1,)type\\'.\\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\\n  File \"/var/azureml-app/main.py\", line 44, in init\\n    driver_module.init()\\n  File \"/var/azureml-app/score_aci.py\", line 19, in init\\n    model.load_weights(os.path.join(output_directory, \"gapnet_weights.h5\"))\\n  File \"/azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 1516, in load_weights\\n    saving.load_weights_from_hdf5_group(f, self.layers)\\n  File \"/azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\", line 798, in load_weights_from_hdf5_group\\n    \\' layers.\\')\\nValueError: You are trying to load a weight file containing 16 layers into a model with 14 layers.\\n\\nWorker exiting (pid: 36)\\nShutting down: Master\\nReason: Worker failed to boot.\\n/bin/bash: /azureml-envs/azureml_464c9d131a2b09e5460ab2df3cd8b1fb/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n2020-02-27T15:11:21,115353854+00:00 - gunicorn/finish 3 0\\n2020-02-27T15:11:21,116384553+00:00 - Exit code 3 is not normal. Killing image.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Inference cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For provisioning_configuration(), if you pick custom values for agent_count and vm_size, and cluster_purpose is not DEV_TEST, then you need to make sure agent_count multiplied by vm_size is greater than or equal to 12 virtual CPUs. For example, if you use a vm_size of \"Standard_D3_v2\", which has 4 virtual CPUs, then you should pick an agent_count of 3 or greater."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skip if already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating..................................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "\n",
    "# Use the default configuration (you can also provide parameters to customize this).\n",
    "# For example, to create a dev/test cluster, use:\n",
    "# prov_config = AksCompute.provisioning_configuration(cluster_purpose = AksCompute.ClusterPurpose.DEV_TEST)\n",
    "#prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "aks_name = 'GAPNet-height'\n",
    "\n",
    "prov_config = prov_config = AksCompute.provisioning_configuration(vm_size = \"Standard_A4_v2\",\n",
    "                                                       agent_count = 3,\n",
    "                                                       location = \"westeurope\")\n",
    "\n",
    "# Create the cluster\n",
    "aks_target = ComputeTarget.create(workspace = ws,\n",
    "                                    name = aks_name,\n",
    "                                    provisioning_configuration = prov_config)\n",
    "\n",
    "# Wait for the create process to complete\n",
    "aks_target.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice, Webservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model on created AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 2, memory_gb = 8, autoscale_enabled=True, autoscale_max_replicas=3, collect_model_data=True, enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='cgm-azureml-prod', subscription_id='9b82ecea-6780-4b85-8acf-d27d79028f07', resource_group='cgm-ml-prod'), name=gapnet_height_s1, id=gapnet_height_s1:1, version=1, tags={}, properties={})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='cgm-azureml-prod', subscription_id='9b82ecea-6780-4b85-8acf-d27d79028f07', resource_group='cgm-ml-prod')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.........\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "aks_target = AksCompute(ws, \"GAPNet-height\")\n",
    "\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 2, memory_gb = 12, autoscale_enabled=True, autoscale_max_replicas=3, collect_model_data=True, enable_app_insights=True)\n",
    "service = Model.deploy(ws, \"aks-gapnet-height-s1\", [model], inference_config_aks, deployment_config, aks_target)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"2020-03-03T08:08:03,315130751+00:00 - iot-server/run \\n/bin/bash: /azureml-envs/azureml_ded9137fa83284e9553ba5265499ce98/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_ded9137fa83284e9553ba5265499ce98/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_ded9137fa83284e9553ba5265499ce98/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n2020-03-03T08:08:03,318944876+00:00 - gunicorn/run \\n2020-03-03T08:08:03,325475489+00:00 - nginx/run \\n/usr/sbin/nginx: /azureml-envs/azureml_ded9137fa83284e9553ba5265499ce98/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_ded9137fa83284e9553ba5265499ce98/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_ded9137fa83284e9553ba5265499ce98/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_ded9137fa83284e9553ba5265499ce98/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_ded9137fa83284e9553ba5265499ce98/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/bin/bash: /azureml-envs/azureml_ded9137fa83284e9553ba5265499ce98/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n2020-03-03T08:08:03,340982895+00:00 - rsyslog/run \\nbash: /azureml-envs/azureml_ded9137fa83284e9553ba5265499ce98/lib/libtinfo.so.5: no version information available (required by bash)\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n/bin/bash: /azureml-envs/azureml_ded9137fa83284e9553ba5265499ce98/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n2020-03-03T08:08:03,502674270+00:00 - iot-server/finish 1 0\\n2020-03-03T08:08:03,507744036+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (12)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 41\\nInitialized PySpark session.\\ngenerated new fontManager\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user's init function\\nFrom /structure/azureml-app/azureml-models/gapnet_height_s1/1/GAPNet/layers.py:123: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nPlease use `layer.add_weight` method instead.\\n2020-03-03 08:08:14.921992: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX\\nTo enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\\n2020-03-03 08:08:14.942113: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194500000 Hz\\n2020-03-03 08:08:14.942728: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x424a040 executing computations on platform Host. Devices:\\n2020-03-03 08:08:14.942774: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\\n2020-03-03 08:08:14.943259: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\\nUsers's init has completed successfully\\nScoring timeout setting is not found. Use default timeout: 3600000 ms\\n\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
