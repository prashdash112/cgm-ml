{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Data Deep Dive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!cp /whhdata/dbconnection.json ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 6,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import dbutils\n",
    "from cgmcore import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob2\n",
    "import os\n",
    "import config\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, clear_output\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_levels = [\"scan\", \"artifact\"]\n",
    "all_datasets = [\"all\", \"training\", \"nottraining\"]\n",
    "all_poses = [\"all\", \"100\", \"101\", \"102\", \"200\", \"201\", \"202\"]\n",
    "all_models = None\n",
    "limits = [0.2, 0.4, 0.6, 1.2, \"all\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all models from DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190925-0556_700-175height-10K_samples_frontal\n",
      "20190914-0703_220-55height\n",
      "20190913-1807_220-55height\n",
      "20190806-1551_220-55height\n",
      "20190723-1119_2550-638weight\n",
      "20190718-2123_2550-638weight\n",
      "20190708-0919_2379-595height\n"
     ]
    }
   ],
   "source": [
    "NO_MODEL_TOKEN=\"No model\"\n",
    "\n",
    "# Getting the models.\n",
    "db_connector = dbutils.connect_to_main_database()\n",
    "select_sql_statement = \"SELECT DISTINCT(type) FROM artifact_quality;\"\n",
    "types = db_connector.execute(select_sql_statement, fetch_all=True)\n",
    "all_models = sorted([t[0] for t in types if len(t[0]) > 20])[::-1]\n",
    "print(\"\\n\".join(all_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Error on scan and artifact level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_model_details(models):\n",
    "    \n",
    "    rows = []\n",
    "    for model in models:\n",
    "        search_path = os.path.join(\"/whhdata/models\", model, \"*.p\")\n",
    "        path = [path for path in glob.glob(search_path) if path.endswith(\"-details.p\")][0]\n",
    "        details = pickle.load(open(path, \"rb\"))\n",
    "\n",
    "        row = []\n",
    "        row.append(model)\n",
    "        row.append(details[\"epochs\"])\n",
    "        row.append(details[\"steps_per_epoch\"])\n",
    "        row.append(details[\"validation_steps\"])\n",
    "        row.append(details[\"batch_size\"])\n",
    "        row.append(details[\"dataset_path\"].replace(\"/localssd/preprocessed/\", \"\"))\n",
    "        row.append(\",\".join(details[\"dataset_parameters\"][\"output_targets\"]))\n",
    "        rows.append(row)\n",
    "\n",
    "    # Create and render dataframe.\n",
    "    headers = (\"Model\", \"Epochs\", \"Steps per Epoch\", \"Validation Steps\", \"Batch Size\", \"Dataset\", \"Targets\")\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cache_entries = {}\n",
    "\n",
    "def error_cache_entry_name(model, level, dataset):\n",
    "    return \"-\".join([model, level, dataset])\n",
    "\n",
    "def update_error_cache_entries(models):\n",
    "    # Create a cache for the visual results.\n",
    "    for model, level, dataset in itertools.product(models, all_levels, all_datasets):\n",
    "\n",
    "        #Cache key.\n",
    "        cache_key = error_cache_entry_name(model, level, dataset)\n",
    "        if cache_key in error_cache_entries:\n",
    "            continue\n",
    "        \n",
    "        print(\"Caching {} {} {}...\".format(model, level, dataset))\n",
    "\n",
    "        # SQL statement for scan level.\n",
    "        if level == \"scan\":\n",
    "            select_sql_statement = \"\"\n",
    "            select_sql_statement += \"SELECT AVG(aq.value) FROM artifact_quality aq\"\n",
    "            select_sql_statement += \" INNER JOIN artifact a ON a.id = aq.artifact_id\"\n",
    "            select_sql_statement += \" WHERE aq.key='mae'\"\n",
    "            select_sql_statement += \" AND aq.type='{}'\".format(model)\n",
    "            if dataset != \"all\":\n",
    "                select_sql_statement += \" AND misc = '{}'\".format(dataset)\n",
    "            select_sql_statement += \" GROUP BY a.qr_code, a.create_date\"\n",
    "            select_sql_statement += \";\"\n",
    "\n",
    "        # SQL statement for artifact level.\n",
    "        elif level == \"artifact\":\n",
    "            select_sql_statement = \"\"\n",
    "            select_sql_statement += \"SELECT value FROM artifact_quality\" \n",
    "            select_sql_statement += \" WHERE type='{}' AND key='mae'\".format(model)\n",
    "            if dataset != \"all\":\n",
    "                select_sql_statement += \" AND misc = '{}'\".format(dataset)\n",
    "            select_sql_statement += \";\"\n",
    "\n",
    "        # Retrieve results from DB.\n",
    "        results = db_connector.execute(select_sql_statement, fetch_all=True)\n",
    "        results = [x[0] for x in results]\n",
    "\n",
    "        # Store in cache.\n",
    "        error_cache_entries[cache_key] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_visualize(models, level, dataset, bins, maximum_loss, density=False):\n",
    "        \n",
    "    update_error_cache_entries(models)\n",
    "    \n",
    "    # Just visualize one model, because no second one is selected.\n",
    "    if len(models) == 1:\n",
    "    \n",
    "        # Get results from cache.\n",
    "        cache_key = error_cache_entry_name(models[0], level, dataset)\n",
    "        results = error_cache_entries[cache_key]\n",
    "        results = [result for result in results if result < maximum_loss]\n",
    "\n",
    "        # Render.\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.hist(results, bins=bins, density=density)\n",
    "        plt.title(\"Error for {} {}s for {} and model {}.\".format(len(results), level, dataset, models[0]))\n",
    "        plt.axvline(1.2, color=\"red\", linestyle='dashed', linewidth=2, label=\"Gold Standard\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    # Compare two models.\n",
    "    else:\n",
    "        \n",
    "        # Render.\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        \n",
    "        for model in models:\n",
    "            cache_key = error_cache_entry_name(model, level, dataset)\n",
    "            results = error_cache_entries[cache_key]\n",
    "            results = [result for result in results if result < maximum_loss]\n",
    "            plt.hist(results, bins=bins, density=density, alpha=0.5 - (len(models) - 1) * 0.05, label=model)\n",
    "    \n",
    "        plt.axvline(1.2, color=\"red\", linestyle='dashed', linewidth=2, label=\"Gold Standard\")\n",
    "        plt.title(\"Error for {} for {}.\".format(level, dataset))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing two networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ce80aaeb8e4300bcc19fa71c260a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model1', options=('20190925-0556_700-175height-10K_samples_frontal…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create interactive widget.\n",
    "@interact(\n",
    "    model1=all_models,\n",
    "    model2=[NO_MODEL_TOKEN] + all_models,\n",
    "    level=all_levels, \n",
    "    dataset=all_datasets, \n",
    "    bins=[100, 200, 400, 800],\n",
    "    maximum_loss=[20, 50, 100, 1000],\n",
    "    density = [True, False]\n",
    ")\n",
    "def interact_visualize(model1, model2, level, dataset, bins, maximum_loss, density):\n",
    "    \n",
    "    if model1 == model2:\n",
    "        print(\"Both models are the same. Will ignore the second.\")\n",
    "        model2 = NO_MODEL_TOKEN\n",
    "        \n",
    "    if model2 == NO_MODEL_TOKEN:\n",
    "        models = [model1]\n",
    "    else:\n",
    "        models = [model1, model2]\n",
    "        \n",
    "    error_visualize(models, level, dataset, bins, maximum_loss, density)\n",
    "    render_model_details(models)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bfa4f275644baea8294bd59003cb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='level', options=('scan', 'artifact'), value='scan'), Dropdown(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create interactive widget.\n",
    "@interact(\n",
    "    level=all_levels, \n",
    "    dataset=all_datasets, \n",
    "    bins=[100, 200, 400, 800],\n",
    "    maximum_loss=[20, 50, 100, 1000],\n",
    "    density = [True, False]\n",
    ")\n",
    "def error_interact_visualize(level, dataset, bins, maximum_loss, density):\n",
    "    \n",
    "    models = [model for model in all_models if \"height\" in model]\n",
    "    print(\"Rendering...\")\n",
    "    error_visualize(models, level, dataset, bins, maximum_loss, density)\n",
    "    render_model_details(models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 8,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# 2. Gold Standard Results on scan and artifact level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "goldstandard_cache_entries = {}\n",
    "\n",
    "def goldstandard_cache_entry_name(model, level, dataset, pose):\n",
    "    return \"-\".join([model, level, dataset, pose])\n",
    "\n",
    "def update_goldstandard_cache_entries(models, poses):\n",
    "    # Create a cache for the visual results.\n",
    "    for model, level, dataset, pose in itertools.product(models, all_levels, all_datasets, poses):\n",
    "\n",
    "        #Cache key.\n",
    "        cache_key = goldstandard_cache_entry_name(model, level, dataset, pose)\n",
    "        if cache_key in goldstandard_cache_entries:\n",
    "            continue\n",
    "        print(\"Caching {}...\".format(cache_key))\n",
    "\n",
    "\n",
    "        # Getting scan count from database.\n",
    "        if level == \"scan\":\n",
    "            select_sql_statement = \"\"\n",
    "            select_sql_statement += \"SELECT COUNT(DISTINCT(m.id))\"\n",
    "            select_sql_statement += \" FROM artifact a\"\n",
    "            select_sql_statement += \" INNER JOIN measure m ON m.id = a.measure_id\"\n",
    "            select_sql_statement += \" INNER JOIN artifact_quality aq ON a.id = aq.artifact_id\"\n",
    "            select_sql_statement += \" WHERE aq.key='mae'\"\n",
    "            select_sql_statement += \" AND aq.type='{}'\".format(model)\n",
    "            if dataset != \"all\":\n",
    "                select_sql_statement += \" AND aq.misc = '{}'\".format(dataset)\n",
    "            if pose != \"all\":\n",
    "                select_sql_statement += \" AND aq.artifact_id LIKE '%_{}_%'\".format(pose)\n",
    "            select_sql_statement += \";\"\n",
    "            all_count = db_connector.execute(select_sql_statement, fetch_one=True)[0]\n",
    "\n",
    "        # Getting artifact count from database.\n",
    "        elif level == \"artifact\":\n",
    "            select_sql_statement = \"\"\n",
    "            select_sql_statement += \"SELECT COUNT(*) FROM artifact_quality aq WHERE aq.type='{}' AND aq.key='mae'\".format(model)\n",
    "            if dataset != \"all\":\n",
    "                select_sql_statement += \" AND aq.misc = '{}'\".format(dataset)\n",
    "            if pose != \"all\":\n",
    "                select_sql_statement += \" AND aq.artifact_id LIKE '%_{}_%'\".format(pose)\n",
    "            select_sql_statement += \";\"\n",
    "            all_count = db_connector.execute(select_sql_statement, fetch_one=True)[0]\n",
    "\n",
    "        # Get the rows.\n",
    "        rows = []\n",
    "        for limit in limits:\n",
    "\n",
    "            # SQL statement for scan level.\n",
    "            if level == \"scan\":\n",
    "                select_sql_statement = \"SELECT COUNT(v) FROM (\"\n",
    "                select_sql_statement += \" SELECT AVG(aq.value) as v FROM artifact_quality aq\"\n",
    "                select_sql_statement += \" INNER JOIN artifact a ON a.id = aq.artifact_id\"\n",
    "                select_sql_statement += \" INNER JOIN measure m ON m.id = a.measure_id\"\n",
    "                select_sql_statement += \" WHERE aq.key='mae'\"\n",
    "                select_sql_statement += \" AND aq.type='{}'\".format(model)\n",
    "                if dataset != \"all\":\n",
    "                    select_sql_statement += \" AND misc = '{}'\".format(dataset)\n",
    "                if pose != \"all\":\n",
    "                    select_sql_statement += \" AND aq.artifact_id LIKE '%_{}_%'\".format(pose)\n",
    "                select_sql_statement += \" GROUP BY m.id\"\n",
    "                select_sql_statement += \") AS subquery\"\n",
    "                if limit != \"all\":\n",
    "                    select_sql_statement += \" WHERE v <= {}\".format(limit)\n",
    "                select_sql_statement += \";\"\n",
    "\n",
    "            # SQL statement for artifact level.\n",
    "            elif level == \"artifact\":\n",
    "                select_sql_statement = \"\"\n",
    "                select_sql_statement += \"SELECT COUNT(aq) FROM artifact_quality aq\" \n",
    "                select_sql_statement += \" WHERE type='{}' AND key='mae'\".format(model)\n",
    "                if dataset != \"all\":\n",
    "                    select_sql_statement += \" AND misc = '{}'\".format(dataset)\n",
    "                if pose != \"all\":\n",
    "                    select_sql_statement += \" AND aq.artifact_id LIKE '%_{}_%'\".format(pose)\n",
    "                if limit != \"all\":\n",
    "                    select_sql_statement += \" AND value <={}\".format(limit)\n",
    "                select_sql_statement += \";\"\n",
    "\n",
    "            # Retrieve results from database.\n",
    "            below_limit_count = db_connector.execute(select_sql_statement, fetch_one=True)[0]\n",
    "\n",
    "            # Compute per cent.\n",
    "            if all_count != 0:\n",
    "                percent = 100 * below_limit_count / all_count\n",
    "            else:\n",
    "                percent = 0\n",
    "\n",
    "            # Come up with a nice description.\n",
    "            description = \"All\"\n",
    "            if limit != \"all\":\n",
    "                description = \"AE <= {}mm\".format(int(10 * limit))\n",
    "\n",
    "            rows.append((description, below_limit_count, round(percent, 2)))\n",
    "\n",
    "        # Store in cache.\n",
    "        goldstandard_cache_entries[cache_key] = rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create interactive widget.\n",
    "@interact(model=all_models, level=all_levels, dataset=all_datasets)\n",
    "def goldstandard_interact_visualize(model, level, dataset):\n",
    "\n",
    "    # Update the cache.\n",
    "    update_goldstandard_cache_entries([model], poses=[\"all\"])\n",
    "    \n",
    "    # Get data from cache.\n",
    "    cache_key = goldstandard_cache_entry_name(model, level, dataset, pose=\"all\")\n",
    "    rows = goldstandard_cache_entries[cache_key]\n",
    "\n",
    "    # Create and render dataframe.\n",
    "    headers = (\"Description\", \"Number\", \"%\")\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widget.\n",
    "@interact(model=all_models, level=all_levels, dataset=all_datasets, pose=all_poses)\n",
    "def goldstandard_interact_visualize(model, level, dataset, pose):\n",
    "\n",
    "    # Update the cache.\n",
    "    update_goldstandard_cache_entries([model], poses=all_poses)\n",
    "    \n",
    "    # Get data from cache.\n",
    "    cache_key = goldstandard_cache_entry_name(model, level, dataset, pose)\n",
    "    rows = goldstandard_cache_entries[cache_key]\n",
    "\n",
    "    # Create and render dataframe.\n",
    "    headers = (\"Description\", \"Number\", \"%\")\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendering measures selected by high/low error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(model=all_models)\n",
    "def another_interact(model):\n",
    "    global selected_model \n",
    "    selected_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_entries(order):\n",
    "\n",
    "    select_sql_statement = \"\"\"\n",
    "        SELECT * FROM (\n",
    "            SELECT AVG(aq.value) AS average, m.id AS measure_id, COUNT(aq) AS count\n",
    "            FROM measure m\n",
    "            INNER JOIN artifact a ON a.measure_id = m.id\n",
    "            INNER JOIN artifact_quality aq ON aq.artifact_id = a.id\n",
    "            WHERE aq.type='{}'\n",
    "            AND aq.key='mae'\n",
    "            GROUP BY m.id\n",
    "        ) AS all_measures\n",
    "        ORDER BY average {}\n",
    "        LIMIT 50\n",
    "        ;\n",
    "        \"\"\".format(selected_model, order)\n",
    "\n",
    "    results = db_connector.execute(select_sql_statement, fetch_all=True)\n",
    "    return results\n",
    "\n",
    "# Graphical user interface.\n",
    "order_widget = None\n",
    "error_widget = None\n",
    "selected_measure_id = None\n",
    "selecte_model = None\n",
    "\n",
    "def clear_and_render_widgets():\n",
    "    clear_output()\n",
    "    if order_widget != None:\n",
    "        display(order_widget)\n",
    "    if error_widget != None:\n",
    "        display(error_widget)\n",
    "    if selected_measure_id != None:\n",
    "        print(\"Rendering...\")\n",
    "        artifacts, targets = get_artifacts_for_measure(selected_measure_id)\n",
    "        utils.render_artifacts_as_gallery(artifacts, targets=targets)\n",
    "\n",
    "def create_order_selector():\n",
    "    global order_widget\n",
    "    options = [\"ASC\", \"DESC\"]\n",
    "    order_widget = widgets.Dropdown(\n",
    "        layout={'width': 'initial'},\n",
    "        options = options,\n",
    "        value=options[0],\n",
    "        description=\"Order\",\n",
    "    )\n",
    "\n",
    "    def on_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            create_error_selector(change['new'])\n",
    "            clear_and_render_widgets()\n",
    "    order_widget.observe(on_change)\n",
    "    \n",
    "    create_error_selector(options[0])\n",
    "\n",
    "    \n",
    "# Create interactive widget.\n",
    "#@interact(order=[\"ASC\", \"DESC\"])\n",
    "def create_error_selector(order):\n",
    "    \n",
    "    results = get_entries(order)\n",
    "    \n",
    "    global selected_measure_id\n",
    "    selected_measure_id = results[0][1]\n",
    "    \n",
    "    global error_widget\n",
    "    options = [\"Error: {} Measure: {}\".format(error, measure_id) for error, measure_id, _ in results]\n",
    "    error_widget = widgets.Dropdown(\n",
    "        layout={'width': 'initial'},\n",
    "        options = options,\n",
    "        value=options[0],\n",
    "        description=\"Measure\",\n",
    "    )\n",
    "\n",
    "    def on_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            index = options.index(change['new'])\n",
    "            global selected_measure_id\n",
    "            selected_measure_id = results[index][1]\n",
    "            clear_and_render_widgets()\n",
    "    error_widget.observe(on_change)\n",
    "    clear_and_render_widgets()\n",
    "        \n",
    "def get_artifacts_for_measure(measure_id):\n",
    "    sql_statement = \"\"\n",
    "    sql_statement += \"SELECT path, height, weight FROM artifact AS a \"\n",
    "    sql_statement += \" INNER JOIN measure m ON m.id = a.measure_id\"\n",
    "    sql_statement += \" WHERE a.measure_id='{}'\".format(measure_id)\n",
    "    sql_statement += \" AND a.type='rgb'\"\n",
    "    sql_statement += \";\"\n",
    "    paths = db_connector.execute(sql_statement, fetch_all=True)\n",
    "    \n",
    "    sql_statement = \"\"\n",
    "    sql_statement += \"SELECT height, weight FROM measure m \"\n",
    "    sql_statement += \" WHERE m.id='{}'\".format(measure_id)\n",
    "    sql_statement += \";\"\n",
    "    targets = db_connector.execute(sql_statement, fetch_one=True)\n",
    "    \n",
    "    return paths, targets\n",
    "  \n",
    "create_order_selector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Available Data in Storage (rgb scans, pcd scans)  => rgb = > 16331 &  pcd => 5049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 4,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": true
   },
   "source": [
    "# TODO Tristan: This can be optimized a lot with glob, I guess.\n",
    "\n",
    "## Getting the number of GB files \n",
    "sum_jpg = 0\n",
    "sum_pcd = 0\n",
    "\n",
    "search_path = config.artifacts_path + \"/\"\n",
    "\n",
    "block = [\".DS_Store\", \"DEMO_TEST_0001\", \"._data\"]\n",
    "for file in tqdm((os.listdir(search_path))):\n",
    "    if(file not in block):\n",
    "        for file1 in os.listdir(search_path + file):\n",
    "            if(file1 == \"measurements\"):\n",
    "                for file2 in os.listdir(search_path + file + \"/\" + file1 + \"/\"):\n",
    "                    for file3 in os.listdir(search_path + file + \"/\" + file1 + \"/\" + file2 + \"/\"):\n",
    "                        if(file3==\"pc\"):\n",
    "                            sum_pcd  = sum_pcd + len(os.listdir(search_path+file+\"/measurements/\"+file2+\"/\"+file3))\n",
    "                        if(file3==\"rgb\"):\n",
    "                            sum_jpg = sum_jpg + len(os.listdir(search_path+file+\"/measurements/\"+file2+\"/\"+file3))\n",
    "print(\"Number of rgb scans in Storage :  \" + str(sum_jpg)) \n",
    "print(\"Number of pc scans in Storage :  \" + str(sum_pcd)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
